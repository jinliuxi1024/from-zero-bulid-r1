# 写在前面

费曼说：  
*What I cannot create, I do not understand.*

我构建这个项目的初衷是因为目前的大语言模型的快速发展，从预训练范式转向推理范式，而大多数的学习教程往往只能点到为止，没有进一步分析其中的细节，比如，如何打磨数据集，如何设计训练过程，如何理解模型架构等等。  

时代的列车呼啸而过，现在的语言模型因为其算力的庞大需求令大多数个人开发者望而却步，其极大的影响了技术的下沉和发展。提供一个高质量的、近工业化的 demo 将有助于后来者拾阶而上，投入到更未来化的建设中去。  

特别说明，这个 demo 是一个进阶的教程，旨在提供一个高性能的训练流程和细节的教学，致力于使用已有材料打磨出一个更为先进的模型，自顶向下的方式分析每一处细节。  

---

## 流程概览

<details>
<summary>点击展开流程详情</summary>

### 模型架构
- 注意力
- 多 token 预测解码
- MoE
- 全局和交错注意力
- 注意力池化

### 分词器
- 训练
- 泛化性

### 数据集处理
- 中英语料
- 推理语料
- 冷启动语料

### 优化器
- AdamW
- Muon

### 参数选择
- 模型参数
- 训练参数

### 训练加速
- 混合精度训练
- 分布式训练
- 梯度累计
- 梯度检查点
- 预训练

### 退火

### 冷启动

### 强化学习
- GRPO
- DAPO
- GSPO

### 指令微调
- SFT
- DPO

### 性能评估
- lm-eval

### 模型量化
- llama.cpp

### 推理部署
- vllm
- sglang
- ollama

</details>

---

## (2025.9.20 更新)

### 一、模型架构

#### 1.1 注意力机制

这一工作从 ChatGPT 3.5 最初得到广泛关注，而后近乎成为目前所有主流大语言模型的主体选择架构。 这个机制更多的参考了数据库的概念而将其抽象出来，当一个词需要对另一个词进行询问时，我们可以将被询问的词看成一个小数据库，对query进行查找对应的key值，并得到value的数据
![Self Attention](images/selfattn.png)
这也是一种特征提取的卷积形式，但是值得关注的应当是其天然的训练并行特点，以往的rnn，cnn等模型，其数据吞吐量训练是低效的，与其说是模型架构推动了语言模型的成功，不如说数据推动了其成功的路径，我们也可以在bert的同期工作中看到并行带来的优势使transformer模型在数据驱动的语言建模上取得了极大的优势。

#### 1.2 前馈层
前馈层通常是由多层mlp组成的非线性变换实现对注意力机制在特征提取到的信息进行进一步的整合。后面的一些工作也有提到，ffn层最重要的作用就是存储模型在训练中得到的知识，我们认为人类语言的交流本质上是极其简洁的，但是我们之所以感觉语言博大精深，是因为噪音，如果交流极其高效，我们是不是可以心灵交流就彼此互相了解呢，有待思考的是，噪音本身组成了知识，我们对外部世界的认知不充分组成了知识，正如模型架构从简洁发展到复杂，再又从复杂回复到简洁，这也就是我所认为moe混合专家架构所采取的合理性，语言建模不一定需要如此庞大的参数。

#### 1.3 MoE混合专家

如果我们品读过 GPT 的最初实现和最近更为先进模型的实现，会发现其结构从一个简洁的架构转向了更为复杂、更具工业化色彩的架构。  
其表现为 **MoE 混合专家** 的引入。最初 Google 引入这一改进的初衷是为了减少推理时的算力而又尽量保持模型的性能。这一架构在后来被 Mistral 和 DeepSeek 发扬光大，并在当下时代成为近乎所有大模型的主体设计。
其

这一工作是经济性的，但是在小模型的架构上，我们该如何考量呢？  
值得肯定的是，由于其稀疏激活的特点，MoE 模型的性能虽然不能与全参数等价的密集模型相平，但是只对有效激活参数来说却略胜一筹。  
